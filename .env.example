# ============================================================================
# Hybrid RAG Q&A System - Environment Configuration
# ============================================================================
# 
# SETUP INSTRUCTIONS:
# 1. Copy this file: cp .env.example .env
# 2. Add your OpenAI API key below (REQUIRED)
# 3. Customize other settings as needed
# 4. Never commit .env to version control!
#
# ============================================================================

# ============================================================================
# REQUIRED: OpenAI API Configuration
# ============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# ============================================================================
# Backend API Configuration
# ============================================================================

# JWT Authentication
# IMPORTANT: Change SECRET_KEY in production!
# Generate secure key: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-change-in-production-use-long-random-string
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# MongoDB Configuration
MONGODB_URL=mongodb://localhost:27017/
MONGODB_DB_NAME=hybrid_rag_qa

# AI Agent Service URL
# Docker: http://ai-agent:8001
# Local: http://localhost:8001
AI_AGENT_URL=http://ai-agent:8001

# ============================================================================
# AI Agent / RAG Configuration
# ============================================================================

# OpenSearch Vector Database
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_USE_SSL=false
OPENSEARCH_VERIFY_CERTS=false
OPENSEARCH_PDF_INDEX=rag-pdf-index
OPENSEARCH_VIDEO_INDEX=rag-video-index

# OpenSearch Authentication (optional - leave empty for no auth)
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=

# ============================================================================
# Embedding Model Configuration
# ============================================================================
# You can change the embedding model to suit your needs.
# Popular options:
#   - sentence-transformers/all-mpnet-base-v2 (768 dim, best quality)
#   - sentence-transformers/all-MiniLM-L6-v2 (384 dim, faster, smaller)
#   - sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (768 dim, multilingual)
#
# IMPORTANT: If you change the model, you MUST:
# 1. Update EMBEDDING_DIMENSION to match the model's output dimension
# 2. Rebuild the index: docker exec -it hybrid-rag-ai-agent python -m src build-index --force-rebuild

EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
EMBEDDING_DIMENSION=768
EMBEDDING_PROVIDER=local
SENTENCE_TRANSFORMERS_HOME=/app/models

# ============================================================================
# LLM Configuration
# ============================================================================

LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500

# Alternative LLM Models:
# - gpt-4o-mini (default, fast and cost-effective)
# - gpt-4o (more capable, higher cost)
# - gpt-4-turbo (balanced performance)
# - gpt-3.5-turbo (fastest, lowest cost)

# ============================================================================
# RAG Pipeline Configuration
# ============================================================================

# Retrieval Settings
RELEVANCE_THRESHOLD=0.7
MAX_RESULTS=5

# Chunking Configuration
CHUNK_SIZE=100
CHUNK_OVERLAP=20
CHUNKING_STRATEGY=sliding_window
MAX_CHUNK_WINDOW=30
MIN_PDF_PARAGRAPHS_PER_PAGE=4

# Pause-based Chunking (for video transcripts)
PAUSE_THRESHOLD=0.5
MIN_SENTENCE_TOKENS=3
MAX_SENTENCE_TOKENS=150

# Logging
LOG_LEVEL=INFO

# ============================================================================
# Frontend Configuration
# ============================================================================

# Backend API URL
# Docker: http://localhost:8000
# Local: http://localhost:8000
REACT_APP_BACKEND_URL=http://localhost:8000

# ============================================================================
# Data Paths (optional - defaults provided)
# ============================================================================

TRANSCRIPT_DIR=data/transcripts
PDF_DIR=data/pdfs

# ============================================================================
# NOTES:
# ============================================================================
# 
# Embedding Model Selection Guide:
# --------------------------------
# Model                                              | Dimension | Speed    | Quality  | Use Case
# ---------------------------------------------------|-----------|----------|----------|------------------
# all-mpnet-base-v2                                  | 768       | Medium   | Best     | Production (default)
# all-MiniLM-L6-v2                                   | 384       | Fast     | Good     | Development/Testing
# paraphrase-multilingual-mpnet-base-v2              | 768       | Medium   | Best     | Multilingual support
# all-distilroberta-v1                               | 768       | Medium   | Good     | Balanced performance
#
# After changing embedding model:
# 1. Update EMBEDDING_MODEL and EMBEDDING_DIMENSION
# 2. Rebuild index: docker exec -it hybrid-rag-ai-agent python -m src build-index --force-rebuild
# 3. Restart services: docker-compose restart ai-agent
#
# ============================================================================
